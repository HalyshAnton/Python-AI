{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7394372,"sourceType":"datasetVersion","datasetId":4257126}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/antongalysh/transfer-learning?scriptVersionId=191664842\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Імпорт бібліотек","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2024-08-08T14:50:42.899958Z","iopub.execute_input":"2024-08-08T14:50:42.900297Z","iopub.status.idle":"2024-08-08T14:50:48.942951Z","shell.execute_reply.started":"2024-08-08T14:50:42.900268Z","shell.execute_reply":"2024-08-08T14:50:48.941842Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Створення ImageFolder","metadata":{}},{"cell_type":"code","source":"data_dir = '/kaggle/input/bone-break-classification-image-dataset/Bone Break Classification/Bone Break Classification'\n\n# Створіть екземпляр ImageFolder\ndataset = datasets.ImageFolder(root=data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T14:50:48.953057Z","iopub.execute_input":"2024-08-08T14:50:48.953366Z","iopub.status.idle":"2024-08-08T14:50:49.194171Z","shell.execute_reply.started":"2024-08-08T14:50:48.95334Z","shell.execute_reply":"2024-08-08T14:50:49.19326Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"**Пояснення:**\n\n* Імпортуємо необхідні бібліотеки: `torch` для основних операцій PyTorch та `datasets` і `transforms` з `torchvision`.\n* `datasets.ImageFolder` використовується для створення екземпляру, що представляє набір даних.\n* Аргумент `root` вказує кореневий каталог, що містить теки ваших класів.\n\n**Розуміння атрибутів об'єкта ImageFolder:**\n\n* **`classes`:** Цей атрибут є списком, що містить назви класів в алфавітному порядку, які відповідають назвам папок у вашому наборі даних.\n* **`class_to_idx`:** Цей словник зіставляє назви класів (ключі) з відповідними цілочисельними індексами (значеннями).\n* **`imgs`:** Цей список містить кортежі, де кожен кортеж представляє зображення та відповідну мітку класу (індекс).","metadata":{}},{"cell_type":"code","source":"dataset.classes","metadata":{"execution":{"iopub.status.busy":"2024-08-08T14:50:49.195386Z","iopub.execute_input":"2024-08-08T14:50:49.195806Z","iopub.status.idle":"2024-08-08T14:50:49.204555Z","shell.execute_reply.started":"2024-08-08T14:50:49.195771Z","shell.execute_reply":"2024-08-08T14:50:49.203436Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"['Avulsion fracture',\n 'Comminuted fracture',\n 'Fracture Dislocation',\n 'Greenstick fracture',\n 'Hairline Fracture',\n 'Impacted fracture',\n 'Longitudinal fracture',\n 'Oblique fracture',\n 'Pathological fracture',\n 'Spiral Fracture']"},"metadata":{}}]},{"cell_type":"markdown","source":"**Розбиття набору даних для навчання та валідації:**\n\n* Поділ вашого набору даних на навчальний та валідаційний набори має вирішальне значення для оцінювання моделі. \n* Функція `random_split` у PyTorch дозволяє випадковим чином розділити набір даних у потрібних пропорціях.","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import random_split\n\ntrain_ratio = 0.8\n\n# Розділіть набір даних\ntrain_data, test_data = random_split(dataset, [train_ratio, 1-train_ratio])","metadata":{"execution":{"iopub.status.busy":"2024-08-08T14:50:49.205935Z","iopub.execute_input":"2024-08-08T14:50:49.206324Z","iopub.status.idle":"2024-08-08T14:50:49.237478Z","shell.execute_reply.started":"2024-08-08T14:50:49.20629Z","shell.execute_reply":"2024-08-08T14:50:49.236512Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Зміна transformer після поділу","metadata":{}},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((224, 224)), # Зміна розміру зображення до 256x256 пікселів\n    transforms.RandomHorizontalFlip(p=0.5), # Випадково перевернути по горизонталі з ймовірністю 50%\n    transforms.ToTensor(), # Перетворити зображення у тензори PyTorch\n    transforms.Normalize(mean=[0.3517, 0.3557, 0.3570],\n                         std=[0.2325, 0.2347, 0.2353]) # нормалізація для моделей\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)), # Зміна розміру зображення до 256x256 пікселів\n    transforms.ToTensor(), # Перетворити зображення у тензори PyTorch\n    transforms.Normalize(mean=[0.3517, 0.3557, 0.3570],\n                         std=[0.2325, 0.2347, 0.2353]) # нормалізація для моделей\n])\n\n\nclass TransformDataset(torch.utils.data.Dataset):\n    def __init__(self, subset, transform=None):\n        self.subset = subset\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        x, y = self.subset[index]\n        if self.transform:\n            x = self.transform(x)\n        return x, y\n        \n    def __len__(self):\n        return len(self.subset)\n\n    \ntrain_data = TransformDataset(train_data, transform = train_transform)\ntest_data = TransformDataset(test_data, transform = test_transform)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T14:50:49.238866Z","iopub.execute_input":"2024-08-08T14:50:49.239185Z","iopub.status.idle":"2024-08-08T14:50:49.249563Z","shell.execute_reply.started":"2024-08-08T14:50:49.239156Z","shell.execute_reply":"2024-08-08T14:50:49.248411Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"**Пояснення:**\n\n* Визначаємо бажане співвідношення розбиття (`train_ratio`) для навчальних даних.\n* Функція `random_split` отримує набір даних та список довжин як аргументи. Довжини визначають кількість вибірок для кожного розбиття.\n* Створює два нових набори даних (`train_data` та `val_data`), що представляють навчальну та валідаційну вибірки відповідно.\n\n**5. Створення завантажувачів даних:**\n\n* PyTorch's `DataLoader` допомагає керувати ефективним завантаженням даних під час навчання. Він дозволяє пакетно завантажувати дані, перемішувати зразки (необов'язково) і обробляти багатопроцесорні дані (необов'язково) для пришвидшення навчання.","metadata":{}},{"cell_type":"markdown","source":"Обчислити параметри для зображень можна і вручну, якщо у вас специфічні зображення","metadata":{}},{"cell_type":"code","source":"means = []\nstds = []\nfor img, _ in train_data:\n    means.append(torch.mean(img, [1, 2]).tolist())\n    stds.append(torch.std(img, [1, 2]).tolist())\n\nmean = torch.mean(torch.tensor(means), [0])\nstd = torch.mean(torch.tensor(stds), [0])\n\nmean, std","metadata":{"execution":{"iopub.status.busy":"2024-08-08T14:50:49.250701Z","iopub.execute_input":"2024-08-08T14:50:49.251099Z","iopub.status.idle":"2024-08-08T14:50:58.46152Z","shell.execute_reply.started":"2024-08-08T14:50:49.251063Z","shell.execute_reply":"2024-08-08T14:50:58.460371Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(tensor([-0.0076, -0.0063, -0.0036]), tensor([1.0035, 1.0040, 1.0039]))"},"metadata":{}}]},{"cell_type":"code","source":"img.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-08T14:50:58.462789Z","iopub.execute_input":"2024-08-08T14:50:58.463089Z","iopub.status.idle":"2024-08-08T14:50:58.469713Z","shell.execute_reply.started":"2024-08-08T14:50:58.463064Z","shell.execute_reply":"2024-08-08T14:50:58.468686Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"torch.Size([3, 224, 224])"},"metadata":{}}]},{"cell_type":"markdown","source":"# Мій випадок","metadata":{}},{"cell_type":"code","source":"# train_data = datasets.ImageFolder(root=data_dir, transform=train_transform,\n#                                   is_valid_file=lambda path: 'Train' in path)\n\n# test_data = datasets.ImageFolder(root=data_dir, transform=test_transform,\n#                                  is_valid_file=lambda path: 'Test' in path)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T14:50:58.473987Z","iopub.execute_input":"2024-08-08T14:50:58.474706Z","iopub.status.idle":"2024-08-08T14:50:58.479162Z","shell.execute_reply.started":"2024-08-08T14:50:58.474669Z","shell.execute_reply":"2024-08-08T14:50:58.478005Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"batch_size = 256\n\n# Створіть завантажувачі даних\ntrain_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\ntest_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T14:50:58.480422Z","iopub.execute_input":"2024-08-08T14:50:58.480792Z","iopub.status.idle":"2024-08-08T14:50:58.494037Z","shell.execute_reply.started":"2024-08-08T14:50:58.480738Z","shell.execute_reply":"2024-08-08T14:50:58.49283Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Трансферне навчання\n\nТрансферне навчання - це потужний метод глибокого навчання, який дозволяє використовувати знання, отримані від попередньо навченої моделі на великому наборі даних, для вирішення нової, пов'язаної з нею задачі. Уявіть, що ви навчили величезну модель ідентифікувати тисячі об'єктів. Навчання з перенесенням дозволяє використовувати цю попередньо навчену модель як відправну точку для нового завдання, наприклад, класифікації різних типів квітів. Повторно використовуючи вивчені ознаки з попередньо навченої моделі, ви можете досягти хороших результатів у новому завданні з меншою кількістю даних і меншим часом навчання порівняно з навчанням моделі з нуля.\n\n**Переваги навчання з перенесенням:**\n\n* **Скорочення часу навчання:** Попередньо навчені моделі вже вивчили потужні представлення ознак з великих наборів даних. Це економить час і обчислювальні ресурси при застосуванні до нових завдань.\n* **Покращена продуктивність:** Трансферне навчання часто дозволяє досягти кращої точності на нових завданнях, особливо з обмеженими даними, порівняно з навчанням моделі з нуля.\n* **Ефективна розробка моделей:** Трансферне навчання дозволяє будувати складні моделі навіть з меншими наборами даних, прискорюючи процес розробки.\n\n![](https://www.researchgate.net/publication/342400905/figure/fig4/AS:905786289057792@1592967688003/The-architecture-of-our-transfer-learning-model.jpg)","metadata":{}},{"cell_type":"markdown","source":"# **Популярні попередньо навчені моделі для комп'ютерного зору:**\n\n* **ImageNet:** Великий набір даних з мільйонами мічених зображень у тисячах категорій об'єктів. Популярні моделі, навчені на ImageNet, включають:\n* **VGG (Very Deep Convolutional Neural Network):** Класична архітектура з глибокими згортковими шарами для вилучення ознак.\n* **ResNet (залишкова мережа):** Вирішує проблему зникаючого градієнта в глибоких мережах, що призводить до кращої продуктивності.\n* **DenseNet (щільно зв'язана згорткова мережа):** Покращує розповсюдження ознак для складних задач з меншою кількістю параметрів.\n\n![](https://glassboxmedicine.com/wp-content/uploads/2020/12/vgg-resnet-googlenet-1.png?w=1024)","metadata":{}},{"cell_type":"markdown","source":"# [Моделі для різних задач](https://pytorch.org/vision/0.9/models.html#torchvision-models)","metadata":{}},{"cell_type":"markdown","source":"# **Заморожування проти тонкого налаштування параметрів:**\n\n* **Заморожування параметрів:** Передбачає, що ваги (параметри) попередньо навченої моделі не підлягають навчанню під час процесу перенесення. Це гарантує, що основні шари виділення ознак залишаються незмінними і фокусує навчання на кінцевих шарах, адаптованих до нового завдання.\n* **Точне налаштування:** Передбачає, що деякі або всі параметри попередньо навченої моделі можуть бути навчені під час навчання з перенесенням. Це дозволяє моделі адаптувати вивчені функції до нової задачі, використовуючи при цьому попередньо набуті знання. Точне налаштування зазвичай застосовується до останніх шарів попередньо навченої моделі, ближче до виходу.","metadata":{}},{"cell_type":"markdown","source":"# [Посилання на документацію по моделях](https://pytorch.org/vision/stable/models.html#classification)","metadata":{}},{"cell_type":"code","source":"from torchvision import models\n\nvgg19 = models.vgg19_bn(pretrained=True)\nvgg19","metadata":{"execution":{"iopub.status.busy":"2024-08-08T14:50:58.495269Z","iopub.execute_input":"2024-08-08T14:50:58.495625Z","iopub.status.idle":"2024-08-08T14:51:04.49797Z","shell.execute_reply.started":"2024-08-08T14:50:58.495579Z","shell.execute_reply":"2024-08-08T14:51:04.496922Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_BN_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/vgg19_bn-c79401a0.pth\" to /root/.cache/torch/hub/checkpoints/vgg19_bn-c79401a0.pth\n100%|██████████| 548M/548M [00:03<00:00, 151MB/s]  \n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (9): ReLU(inplace=True)\n    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (12): ReLU(inplace=True)\n    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (16): ReLU(inplace=True)\n    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (19): ReLU(inplace=True)\n    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (22): ReLU(inplace=True)\n    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (25): ReLU(inplace=True)\n    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (29): ReLU(inplace=True)\n    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (32): ReLU(inplace=True)\n    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (35): ReLU(inplace=True)\n    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (38): ReLU(inplace=True)\n    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (42): ReLU(inplace=True)\n    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (45): ReLU(inplace=True)\n    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (48): ReLU(inplace=True)\n    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (51): ReLU(inplace=True)\n    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"from torch import nn\nimport torch.nn.functional as F\nimport numpy as np\n\n\nclass TransferLearningClassifier(nn.Module):\n    def __init__(self, num_classes=10):\n        super().__init__()\n\n        vgg = models.vgg19_bn(pretrained=True)\n        \n        # від'єднання градієнтів\n        for param in vgg.parameters():\n            param.requires_grad = False\n        \n        # кількість нейронів на виході\n        in_features = vgg.classifier[0].in_features\n        \n        # деактивація останнього шару\n        vgg.classifier = nn.Identity()\n        \n        # створення потрібних шарів\n        self.feature_extractor = vgg\n        \n        self.dropout = nn.Dropout(0.2)\n        self.linear = nn.Linear(in_features, num_classes)\n        \n\n    def forward(self, x):\n        out = self.feature_extractor(x) # (batch, in_features)\n        \n        out = self.dropout(out)\n        out = self.linear(out)\n        \n        return out\n\n\n    def predict(self, X, device='cpu'):\n        X = torch.FloatTensor(np.array(X)).to(device)\n\n        with torch.no_grad():\n            y_pred = F.softmax(self.forward(X), dim=-1)\n\n        return y_pred.cpu().numpy()\n\n\nmodel = TransferLearningClassifier(len(dataset.classes)).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T14:51:04.499605Z","iopub.execute_input":"2024-08-08T14:51:04.499996Z","iopub.status.idle":"2024-08-08T14:51:06.606228Z","shell.execute_reply.started":"2024-08-08T14:51:04.499965Z","shell.execute_reply":"2024-08-08T14:51:06.605253Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"!pip install -q torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-08-08T14:51:06.607482Z","iopub.execute_input":"2024-08-08T14:51:06.607825Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"}]},{"cell_type":"code","source":"from torchsummary import summary\n\nsummary(model, input_size=(3, 224, 224))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# @title Функція для тренування\nimport time\n\ndef train(model, optimizer, loss_fn, train_dl, val_dl,\n          metrics=None, metrics_name=None, epochs=20, device='cpu', task='regression'):\n    '''\n    Runs training loop for classification problems. Returns Keras-style\n    per-epoch history of loss and accuracy over training and validation data.\n\n    Parameters\n    ----------\n    model : nn.Module\n        Neural network model\n    optimizer : torch.optim.Optimizer\n        Search space optimizer (e.g. Adam)\n    loss_fn :\n        Loss function (e.g. nn.CrossEntropyLoss())\n    train_dl :\n        Iterable dataloader for training data.\n    val_dl :\n        Iterable dataloader for validation data.\n    metrics: list\n        List of sklearn metrics functions to be calculated\n    metrics_name: list\n        List of matrics names\n    epochs : int\n        Number of epochs to run\n    device : string\n        Specifies 'cuda' or 'cpu'\n    task : string\n        type of problem. It can be regression, binary or multiclass\n\n    Returns\n    -------\n    Dictionary\n        Similar to Keras' fit(), the output dictionary contains per-epoch\n        history of training loss, training accuracy, validation loss, and\n        validation accuracy.\n    '''\n\n    print('train() called: model=%s, opt=%s(lr=%f), epochs=%d, device=%s\\n' % \\\n          (type(model).__name__, type(optimizer).__name__,\n           optimizer.param_groups[0]['lr'], epochs, device))\n\n    metrics = metrics if metrics else []\n    metrics_name = metrics_name if metrics_name else [metric.__name__ for metric in metrics]\n\n    history = {} # Collects per-epoch loss and metrics like Keras' fit().\n    history['loss'] = []\n    history['val_loss'] = []\n    for name in metrics_name:\n        history[name] = []\n        history[f'val_{name}'] = []\n\n    start_time_train = time.time()\n\n    for epoch in range(epochs):\n\n        # --- TRAIN AND EVALUATE ON TRAINING SET -----------------------------\n        start_time_epoch = time.time()\n\n        model.train()\n        history_train = {name: 0 for name in ['loss']+metrics_name}\n\n        for batch in train_dl:\n            x    = batch[0].to(device)\n            y    = batch[1].to(device)\n            y_pred = model(x)\n            loss = loss_fn(y_pred, y)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            y_pred = y_pred.detach().cpu().numpy()\n            y = y.detach().cpu().numpy()\n\n\n            history_train['loss'] += loss.item() * x.size(0)\n            for name, func in zip(metrics_name, metrics):\n                try:\n                    history_train[name] += func(y, y_pred) * x.size(0)\n                except:\n                    if task == 'binary': y_pred_ = y_pred.round()\n                    elif task == 'multiclass': y_pred_ = y_pred.argmax(axis=-1)\n                    history_train[name] += func(y, y_pred_) * x.size(0)\n\n        for name in history_train:\n            history_train[name] /= len(train_dl.dataset)\n\n\n        # --- EVALUATE ON VALIDATION SET -------------------------------------\n        model.eval()\n        history_val = {'val_' + name: 0 for name in metrics_name+['loss']}\n\n        with torch.no_grad():\n            for batch in val_dl:\n                x    = batch[0].to(device)\n                y    = batch[1].to(device)\n                y_pred = model(x)\n                loss = loss_fn(y_pred, y)\n\n                y_pred = y_pred.cpu().numpy()\n                y = y.cpu().numpy()\n\n                history_val['val_loss'] += loss.item() * x.size(0)\n                for name, func in zip(metrics_name, metrics):\n                    try:\n                        history_val['val_'+name] += func(y, y_pred) * x.size(0)\n                    except:\n                        if task == 'binary': y_pred_ = y_pred.round()\n                        elif task == 'multiclass': y_pred_ = y_pred.argmax(axis=-1)\n\n                        history_val['val_'+name] += func(y, y_pred_) * x.size(0)\n\n        for name in history_val:\n            history_val[name] /= len(val_dl.dataset)\n\n        # PRINTING RESULTS\n\n        end_time_epoch = time.time()\n\n        for name in history_train:\n            history[name].append(history_train[name])\n            history['val_'+name].append(history_val['val_'+name])\n\n        total_time_epoch = end_time_epoch - start_time_epoch\n\n        print(f'Epoch {epoch+1:4d} {total_time_epoch:4.0f}sec', end='\\t')\n        for name in history_train:\n            print(f'{name}: {history[name][-1]:10.3g}', end='\\t')\n            print(f\"val_{name}: {history['val_'+name][-1]:10.3g}\", end='\\t')\n        print()\n\n    # END OF TRAINING LOOP\n\n    end_time_train       = time.time()\n    total_time_train     = end_time_train - start_time_train\n    print()\n    print('Time total:     %5.2f sec' % (total_time_train))\n\n    return history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Визначення функції втрат та оптимізатора\n\nloss_fn = nn.CrossEntropyLoss()\n\n# Оптимізатор (Adam) для оновлення ваг моделі\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\nhistory = train(model, optimizer, loss_fn, train_loader, test_loader,\n                epochs=50,\n                metrics=[accuracy_score],\n                device=device,\n                task='multiclass')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_metric(history, name):\n    plt.title(f\"Model results with {name}\")\n    plt.plot(history[name], label='train')\n    plt.plot(history['val_'+name], label='val')\n    plt.xlabel('Epoch')\n    plt.ylabel(name)\n    plt.legend()\n\n\nplot_metric(history, 'loss')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_metric(history, 'accuracy_score')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import ConfusionMatrixDisplay\n\nmodel = model.to('cpu')  # відключаємо від gpu\n\nloader = torch.utils.data.DataLoader(test_data, batch_size=len(test_data))\nX_test, y_test = next(iter(loader))\n\ny_pred = model.predict(X_test)\n\nConfusionMatrixDisplay.from_predictions(y_test, y_pred.argmax(-1), display_labels=dataset.classes)\nplt.xticks(rotation=90)\nplt.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y_pred.argmax(-1), target_names=dataset.classes))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}