{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPjixIojDMgLKON/Ed7DACD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HalyshAnton/Python-AI/blob/AI_6_lesson/langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# –ü–æ—Å—ñ–±–Ω–∏–∫ –¥–ª—è –ø–æ—á–∞—Ç–∫—ñ–≤—Ü—ñ–≤ –∑ LangChain\n",
        "\n",
        "LangChain - —Ü–µ –Ω–∞–¥—ñ–π–Ω–∏–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫, –ø—Ä–∏–∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –¥–æ–¥–∞—Ç–∫—ñ–≤ –Ω–∞ –æ—Å–Ω–æ–≤—ñ **–≤–µ–ª–∏–∫–∏—Ö –º–æ–≤–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π (LLMs)**. –í—ñ–Ω —Å–ø—Ä–æ—â—É—î —Ä–æ–±–æ—á—ñ –ø—Ä–æ—Ü–µ—Å–∏, —ñ–Ω—Ç–µ–≥—Ä—É—é—á–∏ —Ä—ñ–∑–Ω—ñ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏, —Ç–∞–∫—ñ —è–∫ –ø—ñ–¥–∫–∞–∑–∫–∏, –ø–∞–º'—è—Ç—å —ñ –∑–æ–≤–Ω—ñ—à–Ω—ñ —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏, –¥–æ–∑–≤–æ–ª—è—é—á–∏ —Ä–æ–∑—Ä–æ–±–Ω–∏–∫–∞–º —Å—Ç–≤–æ—Ä—é–≤–∞—Ç–∏ —ñ–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω—ñ –ø—Ä–æ–≥—Ä–∞–º–∏ —à–≤–∏–¥–∫–æ —ñ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ."
      ],
      "metadata": {
        "id": "P06V9UGoyru1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **–Ø–∫ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ LLM –≤ LangChain**\n",
        "\n",
        "### –ö—Ä–æ–∫ 1: –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è –Ω–µ–æ–±—Ö—ñ–¥–Ω–∏—Ö –±—ñ–±–ª—ñ–æ—Ç–µ–∫\n"
      ],
      "metadata": {
        "id": "OcFhfVPczGMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langchain-community huggingface_hub langchain_huggingface"
      ],
      "metadata": {
        "id": "W5aS4QguzOHE"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ö—Ä–æ–∫ 2: –û—Ç—Ä–∏–º–∞–π—Ç–µ —Ç–æ–∫–µ–Ω API Hugging Face\n",
        "–©–æ–± –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –º–æ–¥–µ–ª—ñ, —Ä–æ–∑–º—ñ—â–µ–Ω—ñ –Ω–∞ Hugging Face, –≤–∞–º –ø–æ—Ç—Ä—ñ–±–µ–Ω —Ç–æ–∫–µ–Ω API. –û—Ç—Ä–∏–º–∞–π—Ç–µ –π–æ–≥–æ –∑ [Hugging Face](https://huggingface.co/settings/tokens)."
      ],
      "metadata": {
        "id": "qUJgoD9RzZJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = ''"
      ],
      "metadata": {
        "id": "56tM-BD1za3U"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ö—Ä–æ–∫ 3: –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –º–æ–¥–µ–ª—ñ Mistral-7B-Instruct-v0.2\n",
        "–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—é Hugging Face –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ **Mistral-7B-Instruct-v0.2**."
      ],
      "metadata": {
        "id": "kcJUB9_uzmYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFaceHub\n",
        "\n",
        "# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ –±—ñ–±–ª—ñ–æ—Ç–µ–∫—É LLM\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id='mistralai/Mistral-7B-Instruct-v0.2',\n",
        "    model_kwargs={\n",
        "        \"temperature\": 0.7, # –ù–∞–ª–∞—à—Ç—É–π—Ç–µ –∫—Ä–µ–∞—Ç–∏–≤–Ω—ñ—Å—Ç—å\n",
        "        \"max_length\": 256, # –û–±–º–µ–∂–∏—Ç–∏ –¥–æ–≤–∂–∏–Ω—É –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ\n",
        "        }\n",
        "    )\n",
        "\n",
        "# –ü—Ä–æ—Ç–µ—Å—Ç—É–π—Ç–µ –º–æ–¥–µ–ª—å –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é –ø—Ä–æ—Å—Ç–æ–≥–æ –∑–∞–ø–∏—Ç—É\n",
        "prompt = 'What is LangChain?'\n",
        "response = llm(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtpoLJAszp6M",
        "outputId": "c31b466b-b98e-4e92-e0c3-7e585f4439f8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is LangChain?\n",
            "\n",
            "LangChain is a decentralized language translation platform that uses blockchain technology to provide secure and transparent translation services. It leverages a large pool of human translators and AI language models to provide high-quality translations for various use cases. LangChain aims to disrupt the traditional translation industry by offering faster, cheaper, and more secure translation services through decentralization and token incentives.\n",
            "\n",
            "How does LangChain work?\n",
            "\n",
            "LangChain operates on a decentralized model where\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **–ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –º–æ–¥–µ–ª—ñ: –î–µ—Ç–∞–ª—å–Ω–∏–π –æ–ø–∏—Å**\n",
        "\n",
        "–ü—Ä–∏ –≤–∑–∞—î–º–æ–¥—ñ—ó –∑ LLM –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ —Ç–æ–Ω–∫–æ—ó –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–∂—É—Ç—å —Å—É—Ç—Ç—î–≤–æ –≤–ø–ª–∏–≤–∞—Ç–∏ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ —Ä–æ–±–æ—Ç–∏ –º–æ–¥–µ–ª—ñ. –û—Å—å –¥–µ—Ç–∞–ª—å–Ω–µ –ø–æ—è—Å–Ω–µ–Ω–Ω—è:"
      ],
      "metadata": {
        "id": "rjbdqNHWz45l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞**\n",
        "- **–©–æ —Ä–æ–±–∏—Ç—å:** –ö–µ—Ä—É—î –≤–∏–ø–∞–¥–∫–æ–≤—ñ—Å—Ç—é —É –≤–∏—Ö—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö.\n",
        "- **–î—ñ–∞–ø–∞–∑–æ–Ω:** –í—ñ–¥ 0.0 –¥–æ 1.0 (–∞–±–æ –≤–∏—â–µ).\n",
        "- **–ù–∏–∑—å–∫—ñ –∑–Ω–∞—á–µ–Ω–Ω—è (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, 0.2):** –ú–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä—É—î –¥–µ—Ç–µ—Ä–º—ñ–Ω–æ–≤–∞–Ω—ñ —Ç–∞ —Ü—ñ–ª–µ—Å–ø—Ä—è–º–æ–≤–∞–Ω—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ.\n",
        "- **–í–∏—Å–æ–∫—ñ –∑–Ω–∞—á–µ–Ω–Ω—è (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, 0,8):** –ú–æ–¥–µ–ª—å –¥–∞—î —Ä—ñ–∑–Ω–æ–º–∞–Ω—ñ—Ç–Ω—ñ —Ç–∞ —Ç–≤–æ—Ä—á—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏."
      ],
      "metadata": {
        "id": "JctJgVfaz_Ct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Max Tokens**\n",
        "- **–©–æ —Ä–æ–±–∏—Ç—å:** –û–±–º–µ–∂—É—î –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ–∫–µ–Ω—ñ–≤ (—Å–ª—ñ–≤/—á–∞—Å—Ç–∏–Ω —Å–ª—ñ–≤) —É –≤–∏–≤–µ–¥–µ–Ω–Ω—ñ.\n",
        "- **–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:** –ó–∞–ø–æ–±—ñ–≥–∞—î –æ—Ç—Ä–∏–º–∞–Ω–Ω—é –Ω–∞–¥—Ç–æ –¥–æ–≤–≥–∏—Ö –∞–±–æ —É—Ä—ñ–∑–∞–Ω–∏—Ö –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π."
      ],
      "metadata": {
        "id": "IU6Njib20C_7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Top-p (–≤–∏–±—ñ—Ä–∫–∞ —è–¥—Ä–∞)**.\n",
        "- **–©–æ —Ä–æ–±–∏—Ç—å:** –û–±–º–µ–∂—É—î –≤–∏–±—ñ—Ä–∫—É —Ç–æ–∫–µ–Ω—ñ–≤ –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—ó –∫—É–º—É–ª—è—Ç–∏–≤–Ω–æ—ó –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ `p`.\n",
        "- –î—ñ–∞–ø–∞–∑–æ–Ω:** –≤—ñ–¥ 0.0 –¥–æ 1.0.\n",
        "- **–ù–∏–∑—å–∫—ñ –∑–Ω–∞—á–µ–Ω–Ω—è (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, 0.3):** –í–∏—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ —î –±—ñ–ª—å—à –¥–µ—Ç–µ—Ä–º—ñ–Ω–æ–≤–∞–Ω–∏–º–∏.\n",
        "- **–í–∏—Å–æ–∫—ñ –∑–Ω–∞—á–µ–Ω–Ω—è (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, 0.9):** –†–µ–∑—É–ª—å—Ç–∞—Ç —î –±—ñ–ª—å—à —Ç–≤–æ—Ä—á–∏–º."
      ],
      "metadata": {
        "id": "ZZp988jY0F5-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Frequency Penalty**\n",
        "- **–©–æ –≤—ñ–Ω —Ä–æ–±–∏—Ç—å:** –®—Ç—Ä–∞—Ñ—É—î —Ç–æ–∫–µ–Ω–∏, —è–∫—ñ –≤–∂–µ –∑'—è–≤–ª—è–ª–∏—Å—è, —â–æ–± –∑–∞–æ—Ö–æ—Ç–∏—Ç–∏ —Ä—ñ–∑–Ω–æ–º–∞–Ω—ñ—Ç–Ω—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ.\n",
        "- **–î—ñ–∞–ø–∞–∑–æ–Ω:** –≤—ñ–¥ -2.0 –¥–æ 2.0.\n",
        "- **–í–∏—â—ñ –∑–Ω–∞—á–µ–Ω–Ω—è:** –ü–µ—Ä–µ—à–∫–æ–¥–∂–∞—é—Ç—å –ø–æ–≤—Ç–æ—Ä–µ–Ω–Ω—é.\n",
        "- **–ù–∏–∂—á—ñ –∑–Ω–∞—á–µ–Ω–Ω—è:** –î–æ–∑–≤–æ–ª—è—é—Ç—å –±—ñ–ª—å—à–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω—å."
      ],
      "metadata": {
        "id": "MVsvMrGc0MO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. Presence Penalty**\n",
        "- **–©–æ —Ä–æ–±–∏—Ç—å:** –®—Ç—Ä–∞—Ñ—É—î —Ç–æ–∫–µ–Ω–∏ –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ç–æ–≥–æ, —á–∏ –∑'—è–≤–ª—è—é—Ç—å—Å—è –≤–æ–Ω–∏ —É –≤—Ö—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö.\n",
        "- **–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:** –ó–∞–æ—Ö–æ—á—É—î –≤–≤–æ–¥–∏—Ç–∏ –Ω–æ–≤—ñ –ø–æ–Ω—è—Ç—Ç—è —É –≤—ñ–¥–ø–æ–≤—ñ–¥—è—Ö.\n",
        "- **–î—ñ–∞–ø–∞–∑–æ–Ω:** –≤—ñ–¥ -2.0 –¥–æ 2.0."
      ],
      "metadata": {
        "id": "7EpnbTC90QR0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **–ü—Ä–∏–∫–ª–∞–¥: –û–±'—î–¥–Ω–∞–Ω–Ω—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤**\n",
        "–û—Å—å —è–∫ –≤–∏ –º–æ–∂–µ—Ç–µ –∫–æ–º–±—ñ–Ω—É–≤–∞—Ç–∏ —Ä—ñ–∑–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ø–æ–≤–µ–¥—ñ–Ω–∫–∏:"
      ],
      "metadata": {
        "id": "kr-zzTH80WAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceHub(\n",
        "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "    model_kwargs={\n",
        "        \"temperature\": 0.6,      # –ó–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–∞ –∫—Ä–µ–∞—Ç–∏–≤–Ω—ñ—Å—Ç—å\n",
        "        \"max_length\": 200,       # –í—ñ–¥–ø–æ–≤—ñ–¥—ñ —Å–µ—Ä–µ–¥–Ω—å–æ—ó –¥–æ–≤–∂–∏–Ω–∏\n",
        "        \"top_p\": 0.85,           # –ö—Ä–µ–∞—Ç–∏–≤–Ω–∞ –≤–∏–±—ñ—Ä–∫–∞\n",
        "        \"frequency_penalty\": 0.5 # –ó–∞–æ—Ö–æ—á—É—î–º–æ —Ä—ñ–∑–Ω–æ–º–∞–Ω—ñ—Ç–Ω—ñ—Å—Ç—å\n",
        "    }\n",
        ")\n",
        "\n",
        "response = llm(\"Write short poem about moon\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZ5ERy6f0cVl",
        "outputId": "9b85ef28-9e60-42cc-81f4-7d8bfc848fdc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Write short poem about moon\n",
            "\n",
            "Moon's gentle glow, in night's soft shroud,\n",
            "A beacon in the dark, a calming crowd,\n",
            "Silent witness to the world's repose,\n",
            "A tranquil guide, through life's uncharted coast.\n",
            "\n",
            "Through phases, shifting, in celestial dance,\n",
            "Crescent, quarter, gibbous, full advance,\n",
            "In night's embrace, a constant, comforting light\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **–©–æ —Ç–∞–∫–µ prompt —ñ —è–∫ –π–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏?**\n",
        "\n",
        "–ü—ñ–¥–∫–∞–∑–∫–∞ - —Ü–µ –≤—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ –∞–±–æ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó, —è–∫—ñ –≤–∏ –¥–∞—î—Ç–µ LLM, —â–æ–± —Å–ø—Ä—è–º—É–≤–∞—Ç–∏ –π–æ–≥–æ —Ä–µ–∞–∫—Ü—ñ—é. –°–∫–ª–∞–¥–∞–Ω–Ω—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ—ó –ø—ñ–¥–∫–∞–∑–∫–∏ –º–∞—î –≤–∞–∂–ª–∏–≤–µ –∑–Ω–∞—á–µ–Ω–Ω—è –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –∑–Ω–∞—á—É—â–∏—Ö —ñ —Ç–æ—á–Ω–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤."
      ],
      "metadata": {
        "id": "7a-8EielsNr2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –Ø–∫ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –ø—ñ–¥–∫–∞–∑–∫—É –≤ LangChain\n",
        "–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –ø—ñ–¥–∫–∞–∑–∫–∏ –≤ LangChain –¥—É–∂–µ –ø—Ä–æ—Å—Ç–æ. –û—Å—å –±–∞–∑–æ–≤–∏–π –ø—Ä–∏–∫–ª–∞–¥:"
      ],
      "metadata": {
        "id": "l8SslwdlsPqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFaceHub\n",
        "\n",
        "# Initialize the model\n",
        "llm = HuggingFaceHub(repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "                     model_kwargs={\"temperature\": 0.7})\n",
        "\n",
        "# Define a prompt\n",
        "prompt = \"Explain the benefits of artificial intelligence in education.\"\n",
        "\n",
        "# Get the model's response\n",
        "response = llm(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XaPntFBsfGH",
        "outputId": "86c61ad9-556d-4d24-96b0-98a7459301fd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explain the benefits of artificial intelligence in education.\n",
            "\n",
            "Artificial Intelligence (AI) is transforming various industries and sectors, and education is no exception. AI in education has the potential to significantly enhance the learning experience, making it more personalized, efficient, and effective. Here are some benefits of using AI in education:\n",
            "\n",
            "1. Personalized Learning: AI can analyze a student's learning patterns, strengths, and weaknesses, and provide tailored learning experiences accordingly. This can help students learn at their own pace and in a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **–ü–æ—Ä–∞–¥–∏ —Ç–∞ –ø—Ä–∏–∫–ª–∞–¥–∏ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø—ñ–¥–∫–∞–∑–æ–∫**\n",
        "\n",
        "–°—Ç–≤–æ—Ä–µ–Ω–Ω—è –µ—Ñ–µ–∫—Ç–∏–≤–Ω–∏—Ö –ø—ñ–¥–∫–∞–∑–æ–∫ –≤–∏–º–∞–≥–∞—î —É–≤–∞–≥–∏ –¥–æ —á—ñ—Ç–∫–æ—Å—Ç—ñ, –∫–æ–Ω—Ç–µ–∫—Å—Ç—É —ñ –±–∞–∂–∞–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç—É –≤–∏–≤–æ–¥—É. –ù–∏–∂—á–µ –Ω–∞–≤–µ–¥–µ–Ω–æ –∫—ñ–ª—å–∫–∞ –ø–æ—Ä–∞–¥ —ñ –ø—Ä–∏–∫–ª–∞–¥—ñ–≤:"
      ],
      "metadata": {
        "id": "6IVvHKwKskLJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **–ü–æ—Ä–∞–¥–∏ —â–æ–¥–æ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø—ñ–¥–∫–∞–∑–æ–∫**\n",
        "1. **–ë—É–¥—å—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏–º–∏:** –ß—ñ—Ç–∫–æ —Å—Ñ–æ—Ä–º—É–ª—é–π—Ç–µ, —â–æ –≤–∏ —Ö–æ—á–µ—Ç–µ, —â–æ–± LLM –∑—Ä–æ–±–∏–≤.\n",
        "2. **–ó–∞–±–µ–∑–ø–µ—á—Ç–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç:** –ù–∞–¥–∞–π—Ç–µ –º–æ–¥–µ–ª—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—É –¥–æ–≤—ñ–¥–∫–æ–≤—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é, —â–æ–± –ø–æ–∫—Ä–∞—â–∏—Ç–∏ —ó—ó —Ä–µ–∞–∫—Ü—ñ—é.\n",
        "3. **–í–∏–∑–Ω–∞—á—Ç–µ –≤–∏—Ö—ñ–¥–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç:** –í–∫–∞–∂—ñ—Ç—å, —á–∏ –ø–æ—Ç—Ä—ñ–±–µ–Ω –≤–∞–º —Å–ø–∏—Å–æ–∫, —Ç–∞–±–ª–∏—Ü—è –∞–±–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å.\n",
        "4. **–ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É–π—Ç–µ:** –¢–µ—Å—Ç—É–π—Ç–µ —Ç–∞ –≤–¥–æ—Å–∫–æ–Ω–∞–ª—é–π—Ç–µ —Å–≤–æ—ó –ø—ñ–¥–∫–∞–∑–∫–∏ –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –∫—Ä–∞—â–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤."
      ],
      "metadata": {
        "id": "J9ReJpmcspD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **–ü—Ä–∏–∫–ª–∞–¥ 1: –ü—Ä–æ—Å—Ç–∞ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—è**"
      ],
      "metadata": {
        "id": "CX7w0W74sroh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Describe the role of AI in healthcare in two sentences.\"\n",
        "response = llm(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOR6_L_9syWB",
        "outputId": "ea7d54ab-1af5-4852-c2f0-d6dbcd5362f7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Describe the role of AI in healthcare in two sentences. AI is revolutionizing healthcare by improving diagnostic accuracy, streamlining workflows, predicting disease progression, and enhancing patient outcomes. It is also transforming healthcare operations through automated data analysis, predictive maintenance, and intelligent resource management.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **–ü—Ä–∏–∫–ª–∞–¥ 2: –°—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–µ –≤–∏–≤–µ–¥–µ–Ω–Ω—è**"
      ],
      "metadata": {
        "id": "htT5-dristsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "List three benefits of AI in education:\n",
        "1.\n",
        "2.\n",
        "3.\n",
        "\"\"\"\n",
        "response = llm(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRDe_2D0s0jB",
        "outputId": "952332a4-11cf-4490-9259-0f295b5a5580"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "List three benefits of AI in education:\n",
            "1.\n",
            "2.\n",
            "3.\n",
            "1. Personalized Learning: AI can analyze a student's learning patterns and adapt the educational content accordingly. This can lead to more effective learning and improved academic performance.\n",
            "2. Efficient Administrative Tasks: AI can automate administrative tasks such as grading, scheduling, and record-keeping. This can save teachers time and allow them to focus more on teaching and student interaction.\n",
            "3. Enhanced Accessibility: AI can help make education more accessible to students with dis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **–ü—Ä–∏–∫–ª–∞–¥ 3: –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ-–∫–µ—Ä–æ–≤–∞–Ω–∏–π –∑–∞–ø–∏—Ç**"
      ],
      "metadata": {
        "id": "qk_LxZPasxSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "You are a customer support chatbot.\n",
        "Answer the following question in a friendly and concise tone:\n",
        "What are the refund policies for your service?\n",
        "\"\"\"\n",
        "response = llm(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khE8a5nVs4PI",
        "outputId": "c1ca71c7-81d7-4878-93c4-405741260793"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a customer support chatbot. \n",
            "Answer the following question in a friendly and concise tone:\n",
            "What are the refund policies for your service?\n",
            "\n",
            "Hello there! I'm glad you asked about our refund policy. At our company, we believe in providing top-notch service and ensuring our customers are satisfied with their experience. However, we understand that sometimes things don't work out as planned.\n",
            "\n",
            "If you are not completely satisfied with our service within the first 30 days, please reach out to our customer support team and we will be happy to help you with a full refund. We want to make things right and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **–†–æ–∑—à–∏—Ä–µ–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –∑–∞–ø–∏—Ç—ñ–≤ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é —à–∞–±–ª–æ–Ω—ñ–≤ –∑–∞–ø–∏—Ç—ñ–≤**\n",
        "LangChain –Ω–∞–¥–∞—î ``PromptTemplate`` –¥–ª—è –¥–∏–Ω–∞–º—ñ—á–Ω–æ—ó –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –ø—ñ–¥–∫–∞–∑–æ–∫ —ñ–∑ –∑–∞–ø–æ–≤–Ω—é–≤–∞—á–∞–º–∏:"
      ],
      "metadata": {
        "id": "n19lMuins9MK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Create a template with placeholders\n",
        "template = PromptTemplate(\n",
        "    input_variables=[\"topic\", \"length\"],\n",
        "    template=\"Write a {length} explanation about {topic}.\"\n",
        ")\n",
        "\n",
        "# Fill in the placeholders\n",
        "filled_prompt = template.format(topic=\"machine learning\", length=\"brief\")\n",
        "response = llm(filled_prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JavSUe5tA15",
        "outputId": "a59a6aa6-83d3-454b-922d-c2234adea73b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Write a brief explanation about machine learning.\n",
            "\n",
            "Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to learn and improve from experience without being explicitly programmed. It's a method of data analysis that automates the building of analytical models from data. Machine learning algorithms are designed to learn patterns and make decisions based on data, identifying correlations and making predictions about future events based on the historical data.\n",
            "\n",
            "Machine learning models can be trained on large datasets to recognize patterns, learn from them, and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **–î–æ–ø–æ–º—ñ–∂–Ω—ñ —Å–ª–æ–≤–∞**\n",
        "\n",
        "LangChain –ø—ñ–¥—Ç—Ä–∏–º—É—î —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω—ñ –ø—ñ–¥–∫–∞–∑–∫–∏ –∑—ñ —Å–ø–µ—Ü—ñ–∞–ª—å–Ω–∏–º–∏ ¬´–¥–æ–ø–æ–º—ñ–∂–Ω–∏–º–∏ —Å–ª–æ–≤–∞–º–∏¬ª –∞–±–æ —Å–∏–≥–Ω–∞–ª–∞–º–∏ —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è –¥–ª—è –Ω–∞–¥–∞–Ω–Ω—è —á—ñ—Ç–∫–∏—Ö —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ–π. –û—Å—å —â–æ –æ–∑–Ω–∞—á–∞—é—Ç—å –¥–µ—è–∫—ñ –∑ –Ω–∏—Ö:\n",
        "\n",
        "- **`<< FORMATTING >>`:** –í–∫–∞–∑—É—î –±–∞–∂–∞–Ω—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≤–∏–≤–æ–¥—É, –Ω–∞–ø—Ä–∏–∫–ª–∞–¥, —Å–ø–∏—Å–∫–∏, –º–∞—Ä–∫–µ—Ä–∏ –∞–±–æ —Ç–∞–±–ª–∏—Ü—ñ.\n",
        "- **`<< CANDIDATE PROMPTS >>`:** –ü—Ä–æ–ø–æ–Ω—É—î –º–æ–∂–ª–∏–≤—ñ –≤–∞—Ä—ñ–∞–Ω—Ç–∏ –ø—ñ–¥–∫–∞–∑–∫–∏ –¥–ª—è –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É–≤–∞–Ω–Ω—è –∞–±–æ —É—Ç–æ—á–Ω–µ–Ω–Ω—è.\n",
        "- **`<< INPUT >>`:** –í–∫–∞–∑—É—î, –¥–µ —É –ø—ñ–¥–∫–∞–∑–∫—É –±—É–¥–µ –≤—Å—Ç–∞–≤–ª–µ–Ω–æ –¥–∏–Ω–∞–º—ñ—á–Ω–µ –≤–≤–µ–¥–µ–Ω–Ω—è (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, –¥–∞–Ω—ñ, –Ω–∞–¥–∞–Ω—ñ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º).\n",
        "- **`REMEMBER`:** –í–∫–∞–∑—É—î –º–æ–¥–µ–ª—ñ –∑–±–µ—Ä—ñ–≥–∞—Ç–∏ –∫–ª—é—á–æ–≤—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –¥–ª—è –±–µ–∑–ø–µ—Ä–µ—Ä–≤–Ω–æ—Å—Ç—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π."
      ],
      "metadata": {
        "id": "fSOXWTu8OiBg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **–ü—Ä–∏–∫–ª–∞–¥–∏ –∑ –¥–æ–ø–æ–º—ñ–∂–Ω–∏–º–∏ —Å–ª–æ–≤–∞–º–∏**"
      ],
      "metadata": {
        "id": "-upVdm4oOyKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFaceHub\n",
        "\n",
        "# Initialize the model\n",
        "llm = HuggingFaceHub(repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "                     model_kwargs={\"temperature\": 0.7})\n",
        "\n",
        "# Prompt with formatting instruction\n",
        "prompt = \"\"\"\n",
        "Explain the advantages of renewable energy.\n",
        "<< FORMATTING >>\n",
        "- List three key points.\n",
        "\"\"\"\n",
        "\n",
        "response = llm(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rR8mInCsO5fu",
        "outputId": "19ba14eb-3fcb-4ec5-9cab-9f3bd1f8e032"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Explain the advantages of renewable energy.\n",
            "<< FORMATTING >>\n",
            "- List three key points.\n",
            "- Renewable energy sources are plentiful and inexhaustible, unlike fossil fuels.\n",
            "- They produce minimal greenhouse gas emissions during use, helping to mitigate climate change.\n",
            "- Renewable energy is becoming increasingly cost-competitive with traditional energy sources, making it an attractive investment.\n",
            "- Renewable energy is also more sustainable and can be produced locally, reducing dependence on foreign energy sources and strengthening energy security.\n",
            "< EXPLANATION >\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Create a dynamic prompt template\n",
        "template = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template=\"Describe the importance of {topic} in modern society. << INPUT >>\"\n",
        ")\n",
        "\n",
        "# Generate a prompt\n",
        "prompt = template.format(topic=\"artificial intelligence\")\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6f7SxO8O6JY",
        "outputId": "c0e021d3-284d-4282-92fd-86ae8d536458"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Describe the importance of artificial intelligence in modern society. << INPUT >>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "You are a helpful assistant.\n",
        "\n",
        "REMEMBER: Be concise and avoid overly technical language.\n",
        "\n",
        "Answer the question: What is blockchain technology?\n",
        "\"\"\"\n",
        "response = llm(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDpG-_ljO9KR",
        "outputId": "1d7674f2-affe-4407-e14a-e7879c282721"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a helpful assistant. \n",
            "\n",
            "REMEMBER: Be concise and avoid overly technical language.\n",
            "\n",
            "Answer the question: What is blockchain technology?\n",
            "\n",
            "Blockchain technology is a decentralized digital ledger that records transactions across multiple computers in a secure and transparent way. It allows for the creation of a tamper-evident database that can be used for various applications including digital currencies like Bitcoin. Each block in the chain contains a cryptographic hash of the previous block, creating an unbroken chain of data that is resistant to modification. This ensures the security and integrity of the data recorded in the blockchain.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **–õ–∞–Ω—Ü—é–≥–∏ —É LangChain**\n",
        "\n",
        "–õ–∞–Ω—Ü—é–∂–∫–∏ - —Ü–µ —Ä–æ–±–æ—á—ñ –ø—Ä–æ—Ü–µ—Å–∏, —É —è–∫–∏—Ö –≤–∏—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ –æ–¥–Ω–æ–≥–æ –∫—Ä–æ–∫—É –Ω–∞–¥—Ö–æ–¥—è—Ç—å –Ω–∞ –Ω–∞—Å—Ç—É–ø–Ω–∏–π. LangChain –Ω–∞–¥–∞—î —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏ –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è **–ø—Ä–æ—Å—Ç–∏—Ö –ª–∞–Ω—Ü—é–∂–∫—ñ–≤** —Ç–∞ –±—ñ–ª—å—à —Å–∫–ª–∞–¥–Ω–∏—Ö **–º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ç–æ—Ä—ñ–≤**."
      ],
      "metadata": {
        "id": "iPmC2i5pPH5y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **–ü—Ä–æ—Å—Ç—ñ –ª–∞–Ω—Ü—é–∂–∫–∏**\n",
        "\n",
        "–ü—Ä–æ—Å—Ç–∏–π –ª–∞–Ω—Ü—é–∂–æ–∫ —Å–∫–ª–∞–¥–∞—î—Ç—å—Å—è –∑ –æ–¥–Ω–æ–≥–æ –∑–∞–ø–∏—Ç—É —ñ LLM, –∑ –¥–æ–¥–∞—Ç–∫–æ–≤–æ—é –ø–∞–º'—è—Ç—Ç—é."
      ],
      "metadata": {
        "id": "OB_php12PKLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Define a simple prompt template\n",
        "template = PromptTemplate(\n",
        "    input_variables=[\"name\"],\n",
        "    template=\"Write a friendly greeting for {name}.\"\n",
        ")\n",
        "\n",
        "# Create a simple chain\n",
        "chain = LLMChain(llm=llm, prompt=template)\n",
        "\n",
        "# Run the chain\n",
        "response = chain.run(name=\"Alice\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJdNaE7bPL8Z",
        "outputId": "7a84e177-c173-417b-cae7-7e8ac39e14a8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Write a friendly greeting for Alice.\n",
            "\n",
            "Hello Alice! It's a pleasure to meet you here. I hope you're having a wonderful day so far. Please feel free to explore and let me know if you have any questions or need assistance. Welcome to our community! üòäüå∏ #friendlygreeting #Alice #Welcome! #community #customerservice #hospitality #positivity #kindness #smile #friendliness #greeting #welcomemessage #hello #\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "\n",
        "\n",
        "# prompt template 1\n",
        "first_prompt = PromptTemplate.from_template(\n",
        "    \"What is the best name to describe \\\n",
        "    a company that makes {product}?\"\n",
        ")\n",
        "\n",
        "# Chain 1\n",
        "chain_one = LLMChain(llm=llm, prompt=first_prompt)\n",
        "\n",
        "# prompt template 2\n",
        "second_prompt = PromptTemplate.from_template(\n",
        "    \"Write a short description for the following \\\n",
        "    company:{company_name}\"\n",
        ")\n",
        "# chain 2\n",
        "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
      ],
      "metadata": {
        "id": "piit5JggR82f"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
        "                                             verbose=False\n",
        "                                            )"
      ],
      "metadata": {
        "id": "5JXAUZvSR8yz"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = overall_simple_chain.run(\"hamburger\")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ8F9gH-R8vY",
        "outputId": "7c298893-33bd-4938-cfab-b2b809de79b7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Write a short description for the following     company:Human: What is the best name to describe     a company that makes hamburger?\n",
            "\n",
            "Ass`Assistant: I'd be happy to help brainstorm some names for a company that specializes in making hamburgers! Here are a few suggestions:\n",
            "\n",
            "1. Burger Bliss: This name suggests a high level of satisfaction and enjoyment.\n",
            "2. Hamburger Haven: This name implies a place where one can find excellent hamburgers.\n",
            "3. Burger Bistro: This name has a French touch and could give the company a gourmet or upscale image.\n",
            "4. Burger Barn: This name suggests a warm, inviting, and homely atmosphere.\n",
            "5. Hamburger Hub: This name suggests a central place for hamburgers, making it easy to remember.\n",
            "6. Burger Baron: This name suggests a regal or grand image for the company.\n",
            "7. Hamburger Haven: This name is simple and descriptive, saying exactly what the company does.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J4pTwiAxcLqF"
      },
      "execution_count": 45,
      "outputs": []
    }
  ]
}